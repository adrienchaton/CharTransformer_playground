# Literature for protein representation learning, generation and some misc. ideas

Guidelines: mark the papers already fully-read, keep chronological order (from earliest to latest). Ideally, add model acronyms when the title does not state them.


## General NLP

* Radford / Improving Language Understanding by Generative Pre-Training (GPT) / 2018 / **read**
* Devlin / BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding / 2019 / **read**
* Liu / RoBERTa: A Robustly Optimized BERT Pretraining Approach / 2019 / **read**
* Jain / Attention is not Explanation / 2019
* Wiegreffe / Attention is not not Explanation / 2019
* Xiong / On Layer Normalization in the Transformer Architecture / 2020
* Tay / Efficient Transformers: A Survey / 2020


## General SSL

* Kaku / Intermediate Layers Matter in Momentum Contrastive Self Supervised Learning / 2021


## General reviews

* Ofer / The language of proteins: NLP, machine learning & protein sequences / 2021
* Bepler / Learning the protein language: Evolution, structure, and function / 2021


## Protein Modeling

* Vig / BERTology Meets Biology: Interpreting Attention in Protein Language Models / 2020
* Choromanski / Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers / 2020
* Filipavicius / Pre-training Protein Language Models with Label-Agnostic Binding Pairs Enhances Performance in Downstream Tasks / 2020 / **read**
* Grechishnikova / Transformer neural network for protein‚Äêspecific de novo drug generation as a machine translation problem / 2021
* Rao / MSA Transformer / 2021
* Thumuluri / NetSolP: predicting protein solubility in E. coli using language models / 2021


## Misc. ideas


